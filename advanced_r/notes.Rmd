---
title: "Untitled"
output: html_document
---

```{r}
library(lobstr)
```

You can see when an object gets copied with the help of base::tracemem(). Once you call that function with an object, you’ll get the object’s current address:

```{r}
x <- c(1, 2, 3)
cat(tracemem(x), "\n")
```

From then on, whenever that object is copied, tracemem() will print a message telling you which object was copied, its new address, and the sequence of calls that led to the copy:

```{r}
y <- x
y[[3]] <- 4L
```

If you modify y again, it won’t get copied. That’s because the new object now only has a single name bound to it, so R applies modify-in-place optimisation. We’ll come back to this in Section 2.5.

```{r}
y[[3]] <- 5L
untracemem(x)
```

The same rules for copying also apply to function calls. Take this code:

```{r}
f <- function(a) {
  a
}

x <- c(1, 2, 3)
cat(tracemem(x), "\n")

z <- f(x)
# there's no copy here!

untracemem(x)
```

While f() is running, the a inside the function points to the same value as the x does outside the function:

Because nothing was modified, z and x still point to the same address. If f modified x, z would point to a new address corresponding to a new object created on the modify. 
```{r}
obj_addr(x)
obj_addr(z)
```

It’s not just names (i.e. variables) that point to values; elements of lists do too. Consider this list, which is superficially very similar to the numeric vector above:

```{r}
l1 <- list(1, 2, 3)
obj_addr(l1)
```


```{r}
l2 <- l1
l2[[3]] <- 4
```

This list makes a "shallow" copy. Only the value that was modified (l1[[3]]) is copied. The first 2 values are unmodified, and thus l2[1:2] still point to l1[1:2].

To see values that are shared across lists, use lobstr::ref(). ref() prints the memory address of each object, along with a local ID so that you can easily cross-reference shared components.

```{r}
ref(l1, l2)
```

Data frames are lists of vectors, so copy-on-modify has important consequences when you modify a data frame. Take this data frame as an example:

```{r}
d1 <- data.frame(x = c(1, 5, 6), y = c(2, 4, 3))
```

If you modify a column, only that column needs to be modified; the others will still point to their original references:

```{r}
d2 <- d1
d2[, 2] <- d2[, 2] * 2
ref(d1, d2)
```

However, if you modify a row, every column is modified, which means every column must be copied:

```{r}
d3 <- d1
d3[1, ] <- d3[1, ] * 3
ref(d1,d3)
```

The final place that R uses references is with character vectors4. I usually draw character vectors like this:

```{r}
x <- c("a", "a", "abc", "d")
```

But this is a polite fiction. R actually uses a global string pool where each element of a character vector is a pointer to a unique string in the pool:

You can request that ref() show these references by setting the character argument to TRUE:

```{r}
ref(x, character = TRUE)
```

Why is `tracemem(1:10)` not useful?

This object has no name, so it can't be modified, and hence, `tracemem` can't follow around changes to it's memory address.  

Explain why tracemem() shows two copies when you run this code. Hint: carefully look at the difference between this code and the code shown earlier in the section.

```{r}
x <- c(1L, 2L, 3L)
is.integer(x)
tracemem(x)

x[[3]] <- 4 # NOT an integer! 4 is technically a double
is.integer(x)
```

When x[[3]] is modified to 4, that 4 is of type double. x is of type integer, and atomic vectors can be of only one type. Thus, x is first coerced to a vector of double, then the modify takes place, resulting in 2 copy events. If it was instead `x[[3]] <- 4L`, there would only be one copy event.

Sketch out the relationship between the following objects:

a is unique. b is a list with two duplciated of a. c is another list with b, which is two duplicates of a, a, and another 1:10 unique vector.

```{r}
a <- 1:10
b <- list(a, a)
c <- list(b, a, 1:10)
ref(a,b,c)
```

What happens when you run this code?

```{r}
x <- list(1:10)
x[[2]] <- x
```

First, a name x is made that points to a list object, which contains an integer vector 1:10. Next, x is modified so that the second element is a copy of the original list x containing the integer vector 1:10. This results in a copy-on-modify.
```{r}
obj_addr(x)
ref(x)
```

You can find out how much memory an object takes with lobstr::obj_size()5:

```{r}
obj_size(letters)
obj_size(ggplot2::diamonds)
```

Since the elements of lists are references to values, the size of a list might be much smaller than you expect:

```{r}
x <- runif(1e6)
obj_size(x)
#> 8,000,048 B

y <- list(x, x, x)
obj_size(y)
#> 8,000,128 B
```

y is only 80 bytes6 bigger than x. That’s the size of an empty list with three elements:

```{r}
obj_size(list(NULL,NULL,NULL))
```

Similarly, because R uses a global string pool character vectors take up less memory than you might expect: repeating a string 100 times does not make it take up 100 times as much memory.

```{r}
banana <- "bananas bananas bananas"
obj_size(banana)
#> 136 B
obj_size(rep(banana, 100))
#> 928 B
```

Finally, R 3.5.0 and later versions have a feature that might lead to surprises: ALTREP, short for alternative representation. This allows R to represent certain types of vectors very compactly. The place you are most likely to see this is with : because instead of storing every single number in the sequence, R just stores the first and last number. This means that every sequence, no matter how large, is the same size:

```{r}
obj_size(1:3)
#> 680 B
obj_size(1:1e3)
#> 680 B
obj_size(1:1e6)
#> 680 B
obj_size(1:1e9)
#> 680 B
```

In the following example, why are object.size(y) and obj_size(y) so radically different? Consult the documentation of object.size().

```{r}
y <- rep(list(runif(1e4)), 100)

object.size(y)
#> 8005648 bytes
obj_size(y)
#> 80,896 B
```

From `?obj_size`: 

> Compared to object.size(), obj_size():
> Accounts for all types of shared values, not just strings in the global string pool.
> Includes the size of environments (up to env)
> Accurately measures the size of ALTREP objects.

`object.size` doesn't account for the shared elements in the list, thus it's 100x larger.

```{r}
ref(y)
```

Take the following list. Why is its size somewhat misleading?

```{r}
funs <- list(mean, sd, var)
obj_size(funs)
#> 17,608 B
```

```{r}
ref(funs)
```

From "Answers", It is somewhat misleading, because all three functions are built-in to R as part of the base and stats packages and hence always available.


Predict the output of the following code:

```{r}
a <- runif(1e6)
obj_size(a)
# 8,000,048 B
b <- list(a, a)
obj_size(b)
# 8,000,112 B

# > obj_size(list(NULL,NULL))
# 64 B
# > 64 + 48
# [1] 112

obj_size(a, b)
# 8,000,112 B

b[[1]][[1]] <- 10
obj_size(b)
# copy-on modify takes place. new object size
# is the size of two double vectors of length 100 (8000048 * 2), 
# plus the size of one list (64)
# 8000048 + 8000048 + 64
obj_size(a, b)
# 8000048 + 8000048 + 64

b[[2]][[1]] <- 10
obj_size(b)
# same as obj_size(a, b) above
obj_size(a, b)
# 8000048 + (8000048 + 8000048 + 64) 
```

## Modify in Place

As we’ve seen above, modifying an R object usually creates a copy. There are two exceptions:

* Objects with a single binding get a special performance optimisation.  
* Environments, a special type of object, are always modified in place.

If an object has a single name bound to it, R will modify it in place:

```{r}
# copy and paste in console to see correct memory address behavior
v <- c(1, 2, 3)
obj_size(v)
obj_addr(v)
# 80 B
# [1] "0x7fe69a8dc158"
v[[3]] <- 4
obj_size(v)
obj_addr(v)
# 80 B
# [1] "0x7fe69a8dc158" # same as above!
```

Two complications make predicting exactly when R applies this optimisation challenging:

* When it comes to bindings, R can currently7 only count 0, 1, or many. That means that if an object has two bindings, and one goes away, the reference count does not go back to 1: one less than many is still many. In turn, this means that R will make copies when it sometimes doesn’t need to. 
* Whenever you call the vast majority of functions, it makes a reference to the object. The only exception are specially written “primitive” C functions. These can only be written by R-core and occur mostly in the base package.

Together, these two complications make it hard to predict whether or not a copy will occur. Instead, it’s better to determine it empirically with tracemem().

For loops have a reputation for being slow in R, but often that slowness is caused by every iteration of the loop creating a copy. Consider the following code. It subtracts the median from each column of a large data frame:

Let’s explore the subtleties with a case study using for loops. For loops have a reputation for being slow in R, but often that slowness is caused by every iteration of the loop creating a copy. Consider the following code. It subtracts the median from each column of a large data frame:

```{r}
x <- data.frame(matrix(runif(5 * 1e4), ncol = 5))
medians <- vapply(x, median, numeric(1))

for (i in seq_along(medians)) {
  x[[i]] <- x[[i]] - medians[[i]]
}

cat(tracemem(x), "\n")
#> <0x7f80c429e020> 

for (i in 1:5) {
  x[[i]] <- x[[i]] - medians[[i]]
}
```

In fact, each iteration copies the data frame not once, not twice, but three times! Two copies are made by [[.data.frame, and a further copy8 is made because [[.data.frame is a regular function that increments the reference count of x.

We can reduce the number of copies by using a list instead of a data frame. Modifying a list uses internal C code, so the references are not incremented and only a single copy is made:

```{r}
y <- as.list(x)
cat(tracemem(y), "\n")
#> <0x7f80c5c3de20>
  
for (i in 1:5) {
  y[[i]] <- y[[i]] - medians[[i]]
}
#> tracemem[0x7f80c5c3de20 -> 0x7f80c48de210]: 
```


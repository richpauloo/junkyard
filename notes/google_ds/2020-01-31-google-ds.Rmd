---
title: "Google DS interview prep"
output: 
  github_document:
    toc: true
    #highlight: breezedark
    pandoc_args: --webtex
---

```{r}
library(tidyverse)
```


Topic hierarchy for x:  

1. What is x in both technical and non-technical terms?  
2. Why is x relevant to data science, or at Google specifically? 
3. What are the assumptions of x?  
4. What is the math behind x?  
5. Can you implement x in code?  


# Collecting Data

## Types of Bias

Three types of bias in data collection:

1. **non-response bias**: a large proportion of those sampled do not participate/respond (e.g., you get a 20% completion rate on a survey)
2. **response bias**: when those that respond do not respond truthfully (e.g., they say what they think the researcher wants to hear)  
3. **selection bias**: when the sample population doesn't reflect the true population (e.g., you're studying domestic well properties, but your sample includes both domestic wells and agricultural supply wells). Another example of selection bias that relates to 1. is that the small proportion that responds to a survey may be a self-selecting group, and thus may reflect not reflect the true population. 

All forms of bias may or may not be observable. 


## Data collection strategies

Furthermore, we can sample based on probability or not:

Probability-based sampling: 

1. simple random sample: randomly sample from a population  
2. stratified random sample: sample equally from strata (e.g., sex, age, geographic region)
3. cluster sample: randomly sample clusters, (e.g., to find salary of professors at a school, randomly sample departments, and analyze salaries in those clusters)
```{r}
# table of people giving age and height
d <- tibble(age    = sample(c(20,30,40),   1000, replace = TRUE),
            height = sample(c(50,60),      1000, replace = TRUE),
            gender = sample(c("M","F"),    1000, replace = TRUE),
            group  = sample(LETTERS[1:10], 1000, replace = TRUE))

# simple random sample of 100 individuals (rows) from d
d[sample(1:1000, 100, replace = FALSE), ]

# stratified random sample: gender is the strata.
# take 50 random samples from each strata.
split(d, d$gender) %>% 
  lapply(., function(x) x[ sample(1:nrow(x), 50 , replace=FALSE) , ] )

# cluster sample: groups A:E are the cluster. 
filter(d, group %in% LETTERS[1:5]) 
```

By contrast, non-probability based methods (convenience sampling and gathering volunteers) can be easier and cheaper, but is not representative of the population and is suspect to **selection bias**. 

Probability based methods can be generalized to the population via inference. 


## Types of Studies

**Observational**: think EDA. You can draw correlations and speculate about a relationship, but can't draw cause and effect.

**Experimental**: an experimental study involves random assignment of a treatment, and can draw cause and effect.

For example, in an **observational study** we might observe a relationship between a customer being given a 20% off coupon, and how much they spend at a grocery store. In an **experimental** study, we would randomly assign coupons to customers and test for significant differences in spending between the two groups (e.g., does receiving a coupon make a customer more likely to purchase more?).


## Simpson's paradox

Relationship between variables within subgroups can be **reversed** when the subgroups are combined. 


## Variables

* **response** (dependent): what's of interest  
* **predictor** (independent): what's being used to predict  
* **lurking variable**: a predictor that's not in the model but that influences the response  
* **confounding variable**: a predictor in the model which relates to other predictors, thus impacting the relationship between variables  
  + precisely, in the association of **A** and **B**, **X** is a confounder if it is associated with **BOTH** **A** and **B**.


A lurking variable, when included in the study may be discovered to have a confounding effect. Then we'd call it a confounding variable.  


## Principles of Experimental Design

The purpose of experimental design is to ensure that effects observed in an experiment are likely the result the treatment, rather than by caused by chance.  

* **control**: control for effects due to factors other than the ones of primary interest  
* **randomization**: random distribution of subjects into groups prevents selection bias  
  + randomization ensures that the distribution of subjects into groups is not biased  
* **replication**: ensure a sufficient number of subjects per group to ensure that differences between groups are detectable
  + replication allows for estimating the uncertainty associated with the experiment due to uncontrolled variation 
  + increases precision  
* **stratification**: also called "blocking" means taking measurements at different times (e.g., morning and night) if it's anticipated that there might be differences among these periods  
* **representativeness**: are the subjects representative of the population you want to study? I.e., is the study free of bias (response, non-response, selection)?

If you can, fix a variable. If you can't, consider stratifying it. If you can't fix or stratify the variable, randomize it.


***  

# Probability

Probability of observing event A is $P(A)$, and is bounded by 0 and 1: $0 \le P(A) \le 1$.

Probability of a not observing A is the compliment, $P(A')$, also called $P(A^c) = 1 - P(A)$. 

## Set notation

Used to define the sample space $S$, the set of all possible outcomes that may occur. For example, consider the $S$ for tossing two die:

```{r}
expand.grid(1:6, 1:6)
nrow(expand.grid(1:6, 1:6)) # number of outcomes in S
```

The set for all possible combinations of two coin flips is $S = \{ HH, HT, TH, TT \}$

### Set operations

[union, intersection, compliment, disjoint](https://online.stat.psu.edu/stat500/lesson/2/2.2)  

> **Tip**: read the intersection, $\cap$ as _"AND"_.  

For the disjoint set $A \cap B = \emptyset$, $P(A \cap B) = 0$.

For the union of events that are not mutually exclusive, $P(A \cup B) = P(A) + P(B) - P(A \cap B)$. 


### Conditional probability

Dependent events: 

Probability of A given B, $P(A | B) = P(A \cap B) / P(B)$. 

Probability of B given A, $P(B | A) = P(B \cap A) / P(A)$.

Note that usually, $P(A|B) \ne P(B|A)$.


### Independent events

[Two events are independent if either of the following is true](https://online.stat.psu.edu/stat500/lesson/2/2.6):

$P(A \cap B) = P(A) \cdot P(B)$  
$P(A|B) = P(A)$ and $P(B|A) = P(B)$  


### Review

$P(A \cup B)$ = union = probability of $A$ or $B$  
$P(A \cap B)$ = intersection = probability of $A$ and $B$  
$P(A')$ = compliment = probability of NOT $A$, i.e., $P(B) + P(C) + ... P(N)$  
$P(A | B)$ = conditional = probability of $A$ given $B$

And another rule. Can re-write conditional probability (above) as:

$P(A \cap B) = P(A|B) \cdot P(B)$

Another helpful rule:  

$P(A \: or \: B) = P(A) + P(B) - P(A \cap B)$

### Bayes Theorem

$P(A|B) = \frac{P(B|A) P(A)} {P(B|A) P(A) + P(B|A')P(A')}$


***

# Probability Distributions

Below are examples of discrete (binomial) and continuous (normal) distributions.

Probability **mass** functions $\longrightarrow$ **discrete** variables, and $f(x) = P(X=x)$  

probability **density** functions $\longrightarrow$ **continuous** variables, and $f(x) \ne P(X=x)$  


## Expected value and variance of a discrete random variable

Expected value (mean) is 

$\bar{x} = E(X) = \sum x_i f(x_i)$ where $f(x_i)$ is the probability of event $x_i$, $P(X=x_i)$.  

Variance ($\sigma^2$) is $\sigma^2 = Var(X) = \sum (x_i - \bar{x})^2 f(x_i)$, also written as $\sum x_i^2 f(x_i) - \bar{x}^2$.

Standard deviation $\sigma$ is simply the root of the variance. 

```{r}
# x_i = prior convictions, n = number of prisoners
d <- tibble(xi = 0:4, n = c(80,265,100,40,15))

# probability of event x_i, f(x_i)
d$p <- d$n / sum(d$n)

# expected value = sum(x_i * f(x_i))
ev <- sum(d$xi * d$p) 
ev # 1.29 prior convictions (E doesn't need to be a count)

# variance = sum(x_i - EV) * f(x_i)
var <- sum((d$xi - ev)^2 * d$p)
var

# standard deviation 
sd <- sqrt(var)
sd
```


## Binomial random variables

### Binomial distribution

Special discrete distribution where there are two possible outcomes of a discrete random variable. 

Assumptions (requirements):  

1. $n$ identical trials  
2. Each trial has one of two outcomes (success, failure)  
3. Success probability $p$, same from trial to trial  
4. the $n$ trials are independent  

If these conditions are satisfied, the random variable $X$ = number of successes in $n$ trials is a **binomial random variable** with:  

$\bar{x} = E(X) = np$ (mean)  

$\sigma^2 = Var(X) = np(1-p)$ (variance)  

$\sigma = \sqrt(np(1-p))$ (standard deviation)  


```{r}
# consider 5 independent trials with 25% success. 
# probability of 0 successes: P(X=0)
dbinom(x=0, size=5, prob=0.25)

# probability of 4 or more successes, P(X >= 4)
dbinom(x=4, size=5, prob=0.25) + dbinom(x=5, size=5, prob=0.25)
# same as
sum( dbinom(x=4:5, size=5, prob=0.25) )

# expected value for 5 trails? E(X) = np
5 * 0.25

# standard deviation of successes in 5 trails, 
# SD = sqrt(Var), and Var = np(1 - p)
sqrt(5*0.25*0.75)
```

Consider an experiment with exactly two outcomes (e.g., flipping a coin), and we call heads success. This is a binomial result. We flip the coin 100 times (e.g., 100 independent trials, or experiments). If it's a fair coin, the probability of success (heads), $p =$ 0.5. The expected value is $np =$ 100 * 0.5 = 50. Thus, we expect a normal distribution with mean = 50. 

Here we simulate the probability mass function of a binomial distribution, under varying success probability, and thus expected value ($\mu = E(X) = np$). `size = 100` indicates 100 independent trials, or experiments ($n$). `prob = x` gives the probability of success $p$ across the independent trials, which we vary. `n = 1000` means that for each call to `rbinom` we use 1000 random draws from a binomial distribution with the given $n$ and $p$.

Under varying $p$, the probability mass function is:  

```{r}
# `rbinom` is somewhat confusing, since the n parameter refers to the 
# number of samples to draw, and the SIZE is actually the n in common
# formulations of the binomial distribution
tibble(`p = 0.10` = rbinom(n=1000, size = 100, prob = 0.10),
       `p = 0.25` = rbinom(n=1000, size = 100, prob = 0.25),
       `p = 0.50` = rbinom(n=1000, size = 100, prob = 0.50),
       `p = 0.75` = rbinom(n=1000, size = 100, prob = 0.75),
       `p = 0.90` = rbinom(n=1000, size = 100, prob = 0.90)) %>% 
  pivot_longer(cols = 1:5, names_to = "p", values_to = "val") %>% 
  ggplot(aes(val)) +
  geom_histogram(stat = "density") +
  facet_wrap(~p, scales = "free_y") +
  labs(title = "Probability mass function for binomial distribution",
       subtitle = "1,000 random draws for 100 trials, across varying success probability, p",
       x = "Trails (n)", y = "Probability (P(X = k))") 
```


### Binomial probability

The number of possible samples of size $k$ from a population of size $n$.  

For a binomial random variable:  

$P(X=k) = \left( \frac{n}{k} \right) p^k (1-p)^{(n-k)}$  

where  

$\left( \frac{n}{k} \right) = \frac{n!}{k!(n-k)!}$


## The Normal Distribution

A special case of a distribution of random variable. For a random variable $X$, $P(X = x) = 0$ unlike discrete random variables, for which $P(X = k) = \left( \frac{n}{k} \right) p^k (1-p)^{(n-k)}$. 

Whereas the probability **mass** function of a discrete binomial function is described by $P(X=k) = f(x)$, the probability **density** function of a continuous function at a single location is infinitesimally small, $P(X=X_i) = 0$, and instead is defined as the area under the curve over an interval bounded by $a$ and $b$: $P(a < X < b)$.  

Given a normal distribution with mean $\mu$ and standard deviation, $\sigma$, the z-score of a value $x$ is the difference from the mean divided by the standard deviation, $z = \frac{x-\mu}{\sigma}$. Z-scores essentially allow us to standardize any normal distribution to a standard normal distribution, which then allows us to easily calculate probabilities from known values. Thus, z-scores are useful for comparing between different distributions, and related to the **empirical rule**, also called the **68-95-99.7 rule**: $[\mu - 1\sigma : \mu + 1\sigma]$, $[\mu - 2\sigma : \mu + 2\sigma]$, $[\mu - 3\sigma : \mu + 3\sigma]$ = $P(-1 < Z < 1)$, $P(-2 < Z < 2)$, $P(-3 < Z < 3)$ = 68, 95, 99.7 percent of the area under the normal distribution. 

The max possible z score for a data set is $\frac{(n-1)}{\sqrt n}$.

The standard normal distribution has $\mu = 0$ and $\sigma = 1$, $N(0,1)$:  

```{r}
# simulate a standard normal distribution
tibble(x = seq(-4,4,by=0.1), 
       y = dnorm(seq(-4,4,by=0.1), 0, 1)) %>% 
  ggplot(aes(x, y)) +
  geom_line()
```


## t-distribution

Bell shaped continuous distribution that approaches the normal distribution with increasingly large degrees of freedom (n-1). 

```{r}
x <- seq(-10, 10, by = 0.1)
tibble(xindex = x,
       norm  = dnorm(x),
       df1   = dt(x, 1), 
       df5   = dt(x, 5), 
       df10  = dt(x, 10)) %>% 
  pivot_longer(-xindex, names_to = "dof", values_to = "val") %>% 
  mutate(dof = factor(dof, levels = c('norm','df10', 'df5', 'df1'))) %>% 
  ggplot(aes(xindex, val, color = dof)) +
  geom_line() +
  coord_cartesian(xlim = c(-10, 10)) +
  labs(color = "Degrees of \nFreedom")
```

## Chi-squared distribution

Right-skewed distribution that depends on the degrees of freedom.

```{r}
x <- seq(0, 30, by = 0.1)
tibble(xindex = x,
       df1   = dchisq(x, 1), 
       df5   = dchisq(x, 5), 
       df10  = dchisq(x, 10)) %>% 
  pivot_longer(-xindex, names_to = "dof", values_to = "val") %>% 
  mutate(dof = factor(dof, levels = c('df1', 'df5', 'df10'))) %>% 
  ggplot(aes(xindex, val, color = dof)) +
  geom_line() +
  coord_cartesian(xlim = c(0, 20)) +
  labs(color = "Degrees of \nFreedom")
```

## F-distribution 

Right skewed distribution that depends on two parameters: the numerator and denominator degrees of freedom. 
```{r}
x <- seq(0, 10, by = 0.05)
tibble(xindex = x,
       df11   = df(x, 1, 1), 
       df15   = df(x, 1, 5), 
       df51   = df(x, 5, 1),
       df1010 = df(x, 10, 10)) %>% 
  pivot_longer(-xindex, names_to = "dof", values_to = "val") %>% 
  mutate(dof = factor(dof, levels = c('df11', 'df15', 'df51', 'df1010'))) %>% 
  ggplot(aes(xindex, val, color = dof)) +
  geom_line() +
  coord_cartesian(xlim = c(0, 10)) +
  labs(color = "Degrees of \nFreedom")
```


## Sampling distribution

Sample statistics (e.g., SD, mean) of random samples are also random variables. 

A distribution of sample statistics is called a sampling distribution. 

Suppose we draw 20 samples from a population and compute their mean, $\bar x_1$. We repeat this 1,000 times, generating a distribution of $\bar x_1, \bar x_2, ... \bar x_{1000}$. This is the sampling distribution of the sample mean.  

```{r}
set.seed(7)

# create a population from the standard normal distribution
pop <- rnorm(10000)

# take 20 samples from the population, compute mean, and repeat 1000 times
x <- vector(length = 1000)

for(i in 1:1000) {
  s    <- sample(pop, 30, replace = FALSE)
  x[i] <- mean(s) 
}

tibble(s) %>% 
  ggplot(aes(s)) +
  geom_line(stat="density") +
  labs(title = "Sampling distribution of the sample mean",
       subtitle = "1,000 samples of size 30 from N(0,1)", x = "")
```

If the population is normally distributed, the sampling distribution of the sample mean is also normally distributed, no matter the sample size. The sample mean $\bar x$ has mean $\mu$ and standard deviation equal to standard error, 

$$SD(\bar X) = SE(\bar X) = \frac{\sigma}{\sqrt n}$$ 
Thus the z score of the sample mean is 

$$\frac{\bar x - \mu}{\frac{\sigma}{\sqrt n}}$$

If the sample comes from a distribution that is not normally distributed, the sample mean is still normally distributed if the sample is large, via the Central Limit Theorem. 

If the population is skewed, the sample distribution looks more and more normal when n gets larger.  

```{r}
# simulate normal population
pn <- rnorm(10000,0,1)
ggplot(tibble(pn), aes(pn)) + geom_histogram() + labs(title = "N(0,1)")

# skewed population - beta distribution
pb <- rbeta(10000, 2, 10) 
ggplot(tibble(pb), aes(pb)) + geom_histogram() + labs(title="Beta(2,10)")

# sample extremely small sample sizes from normal population
sample_dist <- function(dist, n, ...) {
  return(sapply(1:10000, function(x) mean(sample(dist, n))))
}

tibble(n2   = sample_dist(pn, n = 2),
       n100 = sample_dist(pn, 100),
       b2   = sample_dist(pb, 2),
       b100 = sample_dist(pb, 100)) %>% 
  pivot_longer(everything(), names_to = "dist", values_to = "sample_mean") %>% 
  ggplot(aes(sample_mean)) +
  geom_line(stat="density") +
  facet_wrap(~dist, scales = "free") +
  labs(subtitle = "Skewed beta population with small sample size -> skewed sampling distribution \nNormal population with small sample size -> normal sampling distribution \nLarge sample size from skewed or normal distribution -> normal sampling distribution")
```

Therefore, CLT tells us that the sampling distribution of the sample mean is normal or approximately normal if either

1. the population distribution is normal  
2. the sample size is large  

And, the sampling distribution has the same mean as the population mean $\mu$, and SE = $\frac{\sigma}{\sqrt n}$. When the population SE $\sigma$ is unknown, we can estimate it with the sample SE $s$. 


## Normal Approximation to the Binomial

Can apply the CLT to find the sampling distribution of the sample proportion, $\hat{p}$. 

Consider a Bernoulli random variable $Y$:  

$$
f(y) = \begin{cases}
  1, \:  success\\
  0, \: failure
\end{cases}
$$
and $p$ is the probability of success.  

The Bernoulli random variable is a special case of the binomial random variable, where the number of trials = 1. There are $n$ values of $Y$ from $Y_1, ... Y_n$.  

Their sum $X$ is $X = \sum_{i=1}^n Y_i$, a binomial random variable with parameters $n$ and $p$.  

The sample proportion $\hat{p} = \frac{X}{n}$, thus the CLT applies for large samples. 

Mean of $\hat{p} = p$. SD = SE = $\sqrt{\frac{p(1-p)}{n}}$.  

Requirements (either of): 

1. $np \ge 5$  
2. $n(1-p) \ge 5$  


# Confidence intervals

In real life, population parameters are rarely known, but methods exist to deal with this.


## Inference

You have data, but not data from the entire population. Inference gives probability statements about the population of interest based on that set of data.  

**Estimation**: use sample information to estimate or predict parameter of interest.  

* point estimates - one parameter, e.g., sample mean or sample proportion  
* interval estimates - e.g., confidence interval which is likely to contain the true parameter of interest.  

**Statistical (hypothesis) Tests**: use sample information to test the truth of a hypothesis.  


## Estimation and confidence intervals

General form of confidence interval = sample statistic $\pm$ margin of error, 

where margin of error = $M \cdot \hat{SE}(estimate)$, and the multiplier M depends on the level of confidence.  

## CI for the population proportion (example)

First, check conditions: $n \hat{p} > 5$ and $n(1-\hat{p}) > 5$? This ensures the sampling distribution is approximately normal.  

Next, use the general form. Z multiplier times the Standard Error. Recall the familiar 1.96 $\pm$ SE for a 95% CI.  

$$
\hat{p} \pm z_{\alpha / 2} \sqrt{\frac{\hat{p}(1-p)}{n}}
$$

where $\alpha$ is typically 0.1 or 0.05, corresponding to the 90% and 95% CIs. Note that the square root term is simply the SE of the estimate.  

**A common misinterpretation of CIs** is that there is a 95% _probability_ of observing an event within the CI. This misses the random nature of the CI which derived from a random sample.  

**CORRECT INTERPRETATION** of the CI: We are 95% _confident_ that the true [statistic of interest] falls between the interval from x to y. We are _confident_ in the _method_ that gives us this specific interval, and if we were to repeat this method many times, we would find that around 95% of the generated CIs would contain the true [statistic of interest]. 


## t-distribution

The t-distribution approaches the z distribution as $n \rightarrow \infty$, are different for different degrees of rfeedom (DOF), and like the z distribution are ccentered at 0.  

```{r}
x <- seq(-10,10,0.01)
tibble(
  x = x,
  `1` = dt(x, df = 1),
  `2` = dt(x, df = 10),
  `20` = dt(x, df = 100),
  `200` = dt(x, df = 500),
  `N(0,1)` = dnorm(x)
) %>% 
  pivot_longer(-x, names_to = "dof", values_to = "y") %>% 
  ggplot(aes(x, y, color = dof)) +
  geom_line() +
  labs(title = "Student's t-distribution",
       subtitle = "Increasingly normal with increasing degrees of freedom = (n-1)",
       color ="Degrees of \nfreedom \n(n-1)", x="",y="Density")
```


# Hypothesis Testing 

Steps:  

1. set up hypotheses  
2. confirm if it's testable with a normal distribution  
3. choose significance level (tolerance to Type I error)  
4. calculate test statistic  
5. convert to probability of observing test statistic or more extreme (p-value)  
6. decide whether nor not to reject null hypothesis   
7. interpret  

***  

Population, Intervention, Comparison, Outcome, Time = **PICOT**. Remember **PICOT** when defining your hypotheses.

***

Type I error: reject $H_0$ when it is TRUE  

* $\alpha$ (significance level) is the probability of committing a Type I error.  

Type II error: fail to reject $H_0$ when $H_0$ is FALSE  

* $\beta$ is the probability of committing a Type II error.  


**Power** = $1 - \beta$ = is the probability $H_0$ is rejected when it is FALSE

Example: 
 
$H_0$: building is not safe  
$H_a$ : building is safe  

Type I error: reject $H_0$ when it's TRUE. The building is not safe, but we incorrectly determined it was safe.  

Type II error: fail to reject $H_0$ when it is FALSE. The building is safe, but we incorrectly determined it was not safe.  

**test statistic**: the sample statistic one uses to either reject $H_0$ or not.  

**p-value**: Commonly misinterpreted as "95% probability that this answer is correct." The correct interpretation of a p-value is: _the probability of obtaining a particular test statistic or a value more extreme, assuming the null is true._ In other words, the p-value itself IS A RANDOM VARIABLE (with a uniform distribution under the null hypothesis and a left skewed distribution under the alternative). If we were to repeat the experiment many times, we would find that, if the null was true, the probability of obtaining our test statistic or a value more extreme is equal to the p-value.   

Interesting relationship to [effect size](https://livefreeordichotomize.com/2018/08/21/p-value-thoughts-a-twitter-follow-up/), and  [null intervals (rather than point nulls)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5863943/pdf/pone.0188299.pdf).  

p-values are easily visualized with the rejection region approach (with a critical value, e.g., $t_{0.05}$).  


***  

statistical significance (passing a test) v practice significance (applicable in the real world)  


## Power  

$\alpha$ is the probability of committing a Type I error [0,1]  
$\beta$ is the probability of committing a Type II error [0,1]  
$Power = 1 - \beta$

Need to increase sample size for $\alpha$ and $\beta$ to decrease, and therefore for power to increase. At a fixed sample size, decreasing $\alpha$ increases $\beta$.

Think of power as the probability [0,1] of not making a Type II error ($1-\beta$).  

Ways to increase power:  

* increase $\alpha$, although this increases P(Type I error)  
* increase $n$, which should, for example, shrink the sample distributions about their mean  
* decrease $\sigma$ of the populations (not possible)  
* decrease effect size you're trying to detect (usually not possible)


## Hypothesis Testing for one-sample proportion and one-sample mean

[Penn State notes](https://online.stat.psu.edu/stat500/lesson/6a/6a.3).




## A/B testing

1. 
2. 
3. 
4. 
5. 


## Confidence intervals

1. 
2. 
3. 
4. 
5. 

# Statistical Learning

## Supervised v Unsupervised learning

## Bias-Variance tradeoff


# Linear Regression

## Simple linear regression

## Multiple linear regression

## Regression considerations


# Classification

## Logistic regression

## Discriminant Analysis

## KNN


# Resampling methods

## Cross-validation

## Bootstrap


# Linear model selection and Regularization

## Subset selection

## Shrinkage methods

## Dimension reduction methods

## Considerations in higher dimensions


# Beyond linearity

## Polynomial regression

## Step functions

## Basis functions

## Regression Splines

## Smoothing splines

## Local regression

## Generalized additive models (GAMs)


# Tree based methods

## Classification and regression trees (CART)

## Bagging, Random Forests, Boosting


# Support Vector Machines

## Maximal Margin Classifier

## Support Vector Classifier

## Support Vector Machines (SVMs)

## SVMs with more than 2 classes


# Unsupervised Learning

## Principal Components Analysis (PCA)

## Clustering methods





***

# Misc topics

## Spatial data analysis

1. 
2. 
3. 
4. 
5. 

## Interpolation

1. 
2. 
3. 
4. 
5. 

## MCMC

1. 
2. 
3. 
4. 
5. 


## Time series analysis

1. 
2. 
3. 
4. 
5. 



Topic hierarchy for frameworks:  

1. What is x?  
2. Why is x relevant to data science, or at Google specifically? 
3. What are some key features of x?

## bash

1. 
2. 
3. 


## Git

1. 
2. 
3. 


## R

1. 
2. 
3. 
 
 
# Additional resources

[Penn State Stat 500](https://online.stat.psu.edu/stat500)
[Karl Browman's courses](https://kbroman.org/pages/teaching.html)
[Karl Browman's Stat 371 ](https://www.biostat.wisc.edu/~kbroman/teaching/stat371/syllabus.html)


# Motivation 
sapply(1:10000, sample_dist, pn, 2),
